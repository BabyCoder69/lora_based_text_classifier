  0%|                                                                                                                               | 0/67500 [00:00<?, ?it/s]
{'input_ids': tensor([[ 5962,  3427, 15745,  2039,  1010, 31947, 38161,   357, 12637,     8,
          8428,   532,   383,   717,  3427, 16807,  1908,   284,   262,    59,
         22977,   468,  5982, 25572, 13066,    11,   262,  3427,  4687,  7732,
           357, 43279, 19415, 30079,   319,  3431,    13, 50256, 50256, 50256,
         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,
         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,
         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],
        [ 1925,    72,    50,  1140,  3292,  5741,   284, 35295,   329,  7695,
            89,    11, 36339,    66,   391,    78,  5741,    11,   508, 45754,
           764, 22515,   351,  3261, 38818,   290,  7388, 20948,    82,   938,
          1622,    11,  3607,   262, 35295,   257,   826,    12, 13638, 31065,
          1362,   287,   262,  3504,   286,   262, 12750,   284, 16829, 24688,
         21835,   290,   406,  2349,  3827, 24406,    11,  1111,  1364,    12,
         13638, 34113,    13, 50256, 50256, 50256, 50256, 50256, 50256],
        [   50,  4798,    25,  7406,   417,  1303,  2670,    26,    82, 32587,
         12682, 28154,   532,  2329,   734,  1933,   706,   262,  8009,   326,
           327,   278,   934, 24365,   481, 12831,  5161, 20766,    26,    51,
         24365,    11, 23178,   468,  3414,   326,   340,  3352,   284,  2822,
          7406,   417, 14620,   329,  3467,     3,  2327,  2997,    13, 50256,
         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,
         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],
        [   37,  5379,  3013,   533, 15349,   287,  4455,  4065,  1907,   370,
         19436,   532,   317,  3931,  6511,  3626, 10822,  4455,  4065,   468,
          8724,   287, 15349, 14794,   290,  7192, 19131,   319,  4530,  1390,
           779,   286,   220, 23611,    26,  2777,   321, 23611,    26,   304,
            12,  4529,   284,  8711,  3884,  2657,  3146,    11,  3644, 15656,
           290,  2691,  7394,    11,  4796,  2732,  2828,   531,  3635,    13,
         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],
        [15633, 14708,   481,  4180, 12147,    11, 13837, 37244,  4394,  6416,
         14708,  1893, 23347,   429,  2879, 23058,   468, 19982,   284,  1394,
         18707,  3271, 37244,  1497,   422,  4609, 47435,  9784,    13, 23058,
           481,  4180,   597,  4040,   416, 12147,   393, 13837,   284,   787,
           257,  1445,   329,   683,   379,   262,   886,   286,   262,  1622,
            13, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,
         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],
        [46509,  5198, 31720,  3958,  7741,  3576,    11,  4492,   357, 18153,
          7311,     8,   532,  1052,  5198,   416, 28040,  2763,   284,   262,
          3594,  9957,  5396,   373,  4388,   319,  3635,    13,   383,  9677,
         27464,   736,   663,  2656,  3958,   319,  6858, 11768,   422,  2237,
          7466,   284,  1440,    13, 50256, 50256, 50256, 50256, 50256, 50256,
         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,
         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],
        [23675,    82, 12568, 20091,   329,  3274,  7178,   286,  7369, 20876,
         17628,  4966,   329, 22169,  5695,   290,   734, 17692,    11,   290,
           262, 18733, 12408,   866,   262,  4047, 28275, 10346,  3761,   287,
           257,  5373,  3321,  1755,    13, 50256, 50256, 50256, 50256, 50256,
         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,
         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,
         50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256],
        [   35, 21317, 34066,  2523, 15723,  1303,  2670,    26,    82, 39577,
          2479, 18248,  1847,    52,  2043,    11,   399,    52,  4535,    53,
          3843,   532,   317, 14005,   756,  7451,   468, 18838,   262, 12584,
          1143,  3793,   286,   257,  6175, 41919,  9610, 28257,   287, 39342,
           615,   315,    13, 13071, 25577, 16528,   286, 12871,  1303,  2670,
            26,    82, 40595,  2059,  1043,   262,  3793,   981, 21976,   262,
           256,   917,   430,   290,  3881, 30648,   329, 34066,    13]],
       device='mps:0'), 'attention_mask': tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0,
         0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0],
        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,
         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]],
       device='mps:0'), 'labels': tensor([3, 1, 2, 3, 1, 1, 1, 3], device='mps:0')}
  File "/Users/haricharan/Documents/desktop-old/Personal/Inter_prep/projects/github/lora_based_text_classifier/main.py", line 133, in <module>
    lora_trainer.train()
  File "/Users/haricharan/anaconda3/envs/lora_classifier/lib/python3.10/site-packages/transformers/trainer.py", line 2123, in train
    return inner_training_loop(
  File "/Users/haricharan/anaconda3/envs/lora_classifier/lib/python3.10/site-packages/transformers/trainer.py", line 2481, in _inner_training_loop
    tr_loss_step = self.training_step(model, inputs, num_items_in_batch)
  File "/Users/haricharan/anaconda3/envs/lora_classifier/lib/python3.10/site-packages/transformers/trainer.py", line 3579, in training_step
    loss = self.compute_loss(model, inputs, num_items_in_batch=num_items_in_batch)
  File "/Users/haricharan/Documents/desktop-old/Personal/Inter_prep/projects/github/lora_based_text_classifier/main.py", line 32, in compute_loss
    labels = inputs.pop("label")
  File "/Users/haricharan/anaconda3/envs/lora_classifier/lib/python3.10/_collections_abc.py", line 962, in pop
    value = self[key]
  File "/Users/haricharan/anaconda3/envs/lora_classifier/lib/python3.10/site-packages/transformers/tokenization_utils_base.py", line 270, in __getitem__
    return self.data[item]
KeyError: 'label'
